{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5a51bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ví Dụ 1\n",
    "# cách 1: Tự xây dựng các bước giải bài toán ràng buộc.\n",
    "# generate data\n",
    "# list of points \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "np.random.seed(21)\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "means = [[2, 2], [4, 1]]\n",
    "cov = [[.5, .2], [.2, .5]]\n",
    "N = 100\n",
    "X0 = np.random.multivariate_normal(means[0], cov, N)\n",
    "X1 = np.random.multivariate_normal(means[1], cov, N)\n",
    "X1[-1, :] = [2.7, 2]\n",
    "X = np.concatenate((X0.T, X1.T), axis = 1)\n",
    "y = np.concatenate((np.ones((1, N)), -1*np.ones((1, N))), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "992c63d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(5, 5))  \n",
    "\n",
    "ani = plt.cla()\n",
    "#plot points\n",
    "ani = plt.plot(X0.T[0, :], X0.T[1, :], 'b^', markersize = 5, alpha = .8)\n",
    "ani = plt.plot(X1.T[0, :], X1.T[1, :], 'ro', markersize = 5, alpha = .8)\n",
    "ani = plt.axis([-1 , 6, -1, 6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0389c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = \n",
      " [[5.44024400e-08 1.60248993e-07 1.15680626e+02 6.04097017e-08\n",
      "  4.56848171e-08 2.79472410e-08 6.95025240e-08 6.40525997e-08\n",
      "  4.27557887e-08 5.48335204e-08 1.76037860e-07 2.00000000e+02\n",
      "  5.01490982e-08 3.15135467e-08 3.61403882e-08 2.66327125e-08\n",
      "  2.00000000e+02 2.76802488e-08 3.15523937e-08 4.32255484e-08\n",
      "  4.31172279e-08 2.38353668e-08 6.80984429e-08 1.55301487e-07\n",
      "  3.28354863e-07 3.50315655e-08 3.55787254e-08 3.68517446e-08\n",
      "  2.77088026e-08 2.48801001e-08 3.33417093e-08 7.10695613e-08\n",
      "  3.16472377e-08 5.69256798e-08 3.50102098e-08 4.36172744e-08\n",
      "  1.99999994e+02 1.82789994e-08 1.82433002e-08 6.94218761e-08\n",
      "  1.41546577e-07 5.06887356e-08 3.26159868e-08 3.08565662e-08\n",
      "  1.34269920e-07 2.00160223e-07 2.33871401e-08 4.00441212e-08\n",
      "  1.97171917e-08 2.05683461e-07 8.10364620e-08 4.05136635e-08\n",
      "  3.35264789e-08 3.62109628e-08 1.58953833e-07 4.53639653e-08\n",
      "  1.34819547e-07 1.38138332e-07 6.65393734e-08 1.57268560e-07\n",
      "  3.20913450e-08 5.08992472e-08 1.04314960e-07 6.20507167e-08\n",
      "  3.12546040e-08 1.87368599e-07 3.39115098e-08 6.02205333e-08\n",
      "  3.78667167e-08 3.88158509e-08 5.25824803e-08 4.01993758e-08\n",
      "  5.07073066e-08 7.58569977e-08 5.16795489e-08 3.81246061e-08\n",
      "  1.63164560e-08 3.83966639e-08 9.89719526e-08 4.53810832e-07\n",
      "  6.71393975e-08 3.20657464e-08 6.14799268e-08 4.71078898e-08\n",
      "  3.06038492e-08 3.95750679e-08 1.27728853e-06 4.79351305e-08\n",
      "  1.32869162e-07 6.28572384e-08 1.38884023e-07 2.61921729e-08\n",
      "  7.34062170e-08 3.99712037e-08 5.22849816e-08 3.00186805e-08\n",
      "  1.59085743e-07 3.87486264e-08 3.92607851e-08 3.66262686e-08\n",
      "  4.15549124e-08 2.54005765e-08 6.08497789e-08 2.83994616e-08\n",
      "  8.61364113e-08 2.79554477e-08 7.30618112e-08 1.00556229e-07\n",
      "  2.63865952e-08 5.02303717e-08 4.10444788e-08 2.07848950e-07\n",
      "  8.21448552e-08 4.22198692e-08 2.00916278e-08 1.23546770e-07\n",
      "  2.11361934e-08 2.86588877e-08 5.42661061e-08 3.14721197e-08\n",
      "  6.53711725e-08 5.31903676e-08 3.44397169e-08 3.88730252e-06\n",
      "  9.79738819e+01 2.67479637e-08 4.53222683e-07 3.15823450e-08\n",
      "  3.23384039e-08 3.98946298e-08 3.97447887e-08 4.25781838e-08\n",
      "  3.23918678e-08 3.15683864e-08 2.92446072e-08 3.22305972e-08\n",
      "  4.59225879e-08 3.33388750e-08 5.19584885e-08 4.60635184e-08\n",
      "  5.39102850e-08 1.99440817e-08 3.32687510e-08 1.99999999e+02\n",
      "  2.89084932e-08 1.01568138e-07 3.57183190e-08 5.01552008e-08\n",
      "  5.65238201e-08 5.18923086e-08 2.94697649e-08 3.50898322e-08\n",
      "  3.96533103e-08 8.66122872e-08 4.19256416e-08 3.63334241e-08\n",
      "  5.99753816e-08 6.85681935e-08 1.91034116e-06 1.10655306e-06\n",
      "  1.15442355e-07 4.21471234e-08 1.02501586e-07 1.77067394e+01\n",
      "  1.81557949e-07 1.99999994e+02 8.79123398e-08 6.85649120e-08\n",
      "  3.24589782e-08 2.45793478e-08 6.38438592e-08 3.79709476e-08\n",
      "  2.20405758e-07 2.55967584e-08 1.44595723e-07 1.04190095e-07\n",
      "  3.86581840e-08 1.61683231e-07 1.58114543e-08 2.96683066e-08\n",
      "  1.56350346e-07 3.29836836e-08 6.94910543e-08 2.09639963e-08\n",
      "  5.66760578e-08 6.36474344e-08 8.52195321e-08 4.77811251e-08\n",
      "  5.98789843e-08 2.50792373e-08 4.43462763e-08 5.80753856e-08\n",
      "  6.23354627e-08 9.17761987e-08 5.36371498e-08 3.74534450e-08\n",
      "  4.02481268e-08 7.28334865e-08 4.49013138e-08 2.00000000e+02]]\n"
     ]
    }
   ],
   "source": [
    "from cvxopt import matrix, solvers\n",
    "C=200\n",
    "\n",
    "# build K\n",
    "V = np.concatenate((X0.T, -X1.T), axis = 1)\n",
    "K = matrix(V.T.dot(V))\n",
    "\n",
    "p = matrix(-np.ones((2*N, 1)))\n",
    "# build A, b, G, h \n",
    "G = matrix(np.vstack((-np.eye(2*N), np.eye(2*N))))\n",
    "\n",
    "h = matrix(np.vstack((np.zeros((2*N, 1)), C*np.ones((2*N, 1)))))\n",
    "A = matrix(y.reshape((-1, 2*N))) \n",
    "b = matrix(np.zeros((1, 1))) \n",
    "solvers.options['show_progress'] = False\n",
    "sol = solvers.qp(K, p, G, h, A, b)\n",
    "\n",
    "l = np.array(sol['x'])\n",
    "print('lambda = \\n', l.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8834fd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 200)\n",
      "[[-3.49214853  2.83441932]] 6.217946644623659\n"
     ]
    }
   ],
   "source": [
    "S = np.where(l > 1e-5)[0] # support set \n",
    "S2 = np.where(l < .999*C)[0] \n",
    "print(y.shape)\n",
    "M = [val for val in S if val in S2] # intersection of two lists\n",
    "\n",
    "XT = X.T # we need each column to be one data point in this alg\n",
    "VS = V[:, S]\n",
    "lS = l[S]\n",
    "yM = y[:,M]\n",
    "XM = X[:, M]\n",
    "\n",
    "w_dual = VS.dot(lS).reshape(-1, 1)\n",
    "w_0_dual = np.mean(yM.T - w_dual.T.dot(XM))\n",
    "print(w_dual.T, w_0_dual) \n",
    "w = w_dual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "046c1c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w =  [[-3.49143421  2.83300814]]\n",
      "w_0 =  [6.21730668]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# Copy and put code for generate data here\n",
    "y1 = y.reshape((2*N,))\n",
    "X1 = X.T # each sample is one row\n",
    "clf = SVC(kernel = 'linear', C = 100) # just a big number \n",
    "# if C is small, method will be “SoftMagin SVM”, \n",
    "# if C is large enough, method is near to hard margin\n",
    "clf.fit(X1, y1) \n",
    "\n",
    "w = clf.coef_\n",
    "w0 = clf.intercept_\n",
    "print('w = ', w)\n",
    "print('w_0 = ', w0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1c8fac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient different: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# cách 2\n",
    "means = [[2, 2], [4, 1]]\n",
    "cov = [[.5, .2], [.2, .5]]\n",
    "N = 100\n",
    "X0 = np.random.multivariate_normal(means[0], cov, N)\n",
    "X1 = np.random.multivariate_normal(means[1], cov, N)\n",
    "X1[-1, :] = [2.7, 2]\n",
    "X = np.concatenate((X0.T, X1.T), axis = 1)\n",
    "y = np.concatenate((np.ones((1, N)), -1*np.ones((1, N))), axis = 1)\n",
    "\n",
    "X0_bar = np.vstack((X0.T, np.ones((1, N)))) # extended data\n",
    "X1_bar = np.vstack((X1.T, np.ones((1, N)))) # extended data \n",
    "\n",
    "Z = np.hstack((X0_bar, - X1_bar)) # as in (22)\n",
    "lam = 1./C\n",
    "\n",
    "def cost(w):\n",
    "    u = w.T.dot(Z) # as in (23)\n",
    "    return (np.sum(np.maximum(0, 1 - u)) + \\\n",
    "        .5*lam*np.sum(w*w)) - .5*lam*w[-1]*w[-1] # no bias \n",
    "\n",
    "def grad(w):\n",
    "    u = w.T.dot(Z) # as in (23)\n",
    "    H = np.where(u < 1)[1]\n",
    "    ZS = Z[:, H]\n",
    "    g = (-np.sum(ZS, axis = 1, keepdims = True) + lam*w)\n",
    "    g[-1] -= lam*w[-1] # no weight decay on bias\n",
    "    return g\n",
    "\n",
    "eps = 1e-6\n",
    "def num_grad(w):\n",
    "    g = np.zeros_like(w)\n",
    "    for i in range(len(w)):\n",
    "        wp = w.copy()\n",
    "        wm = w.copy()\n",
    "        wp[i] += eps \n",
    "        wm[i] -= eps \n",
    "        g[i] = (cost(wp) - cost(wm))/(2*eps)\n",
    "    return g \n",
    "\n",
    "w0 = np.random.randn(X0_bar.shape[0], 1) \n",
    "g1 = grad(w0)\n",
    "g2 = num_grad(w0)\n",
    "diff = np.linalg.norm(g1 - g2)\n",
    "print('Gradient different: %f' %diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f34789f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 cost: 236.771456\n",
      "iter 10001 cost: 15.229142\n",
      "iter 20001 cost: 15.189826\n",
      "iter 30001 cost: 15.193203\n",
      "iter 40001 cost: 15.189807\n",
      "iter 50001 cost: 15.190172\n",
      "iter 60001 cost: 15.197053\n",
      "iter 70001 cost: 15.197417\n",
      "iter 80001 cost: 15.194717\n",
      "iter 90001 cost: 15.193799\n",
      "iter 100001 cost: 15.191909\n",
      "iter 110001 cost: 15.198789\n",
      "iter 120001 cost: 15.199155\n",
      "iter 130001 cost: 15.191335\n",
      "iter 140001 cost: 15.191478\n",
      "iter 150001 cost: 15.197770\n",
      "iter 160001 cost: 15.196851\n",
      "iter 170001 cost: 15.190614\n",
      "iter 180001 cost: 15.190979\n",
      "iter 190001 cost: 15.197860\n",
      "iter 200001 cost: 15.198225\n",
      "iter 210001 cost: 15.192816\n",
      "iter 220001 cost: 15.191898\n",
      "iter 230001 cost: 15.192716\n",
      "iter 240001 cost: 15.189319\n",
      "iter 250001 cost: 15.189684\n",
      "iter 260001 cost: 15.196565\n",
      "iter 270001 cost: 15.196930\n",
      "iter 280001 cost: 15.195869\n",
      "iter 290001 cost: 15.194950\n",
      "iter 300001 cost: 15.191421\n",
      "iter 310001 cost: 15.191786\n",
      "iter 320001 cost: 15.192151\n",
      "iter 330001 cost: 15.199032\n",
      "iter 340001 cost: 15.189273\n",
      "iter 350001 cost: 15.191632\n",
      "iter 360001 cost: 15.198003\n",
      "iter 370001 cost: 15.190127\n",
      "iter 380001 cost: 15.190491\n",
      "iter 390001 cost: 15.197372\n",
      "iter 400001 cost: 15.197737\n",
      "iter 410001 cost: 15.193967\n",
      "iter 420001 cost: 15.193049\n",
      "iter 430001 cost: 15.192229\n",
      "iter 440001 cost: 15.192593\n",
      "iter 450001 cost: 15.199474\n",
      "iter 460001 cost: 15.191314\n",
      "iter 470001 cost: 15.191456\n",
      "iter 480001 cost: 15.197019\n",
      "iter 490001 cost: 15.196101\n",
      "iter 500001 cost: 15.190934\n",
      "iter 510001 cost: 15.191299\n",
      "iter 520001 cost: 15.198180\n",
      "iter 530001 cost: 15.198544\n",
      "iter 540001 cost: 15.192066\n",
      "iter 550001 cost: 15.191642\n",
      "iter 560001 cost: 15.193036\n",
      "iter 570001 cost: 15.198235\n",
      "iter 580001 cost: 15.190004\n",
      "iter 590001 cost: 15.196885\n",
      "iter 600001 cost: 15.197250\n",
      "iter 610001 cost: 15.195119\n",
      "iter 620001 cost: 15.194200\n",
      "iter 630001 cost: 15.191741\n",
      "iter 640001 cost: 15.192106\n",
      "iter 650001 cost: 15.198987\n",
      "iter 660001 cost: 15.199352\n",
      "iter 670001 cost: 15.191467\n",
      "iter 680001 cost: 15.191610\n",
      "iter 690001 cost: 15.197252\n",
      "iter 700001 cost: 15.196333\n",
      "iter 710001 cost: 15.190812\n",
      "iter 720001 cost: 15.197692\n",
      "iter 730001 cost: 15.198057\n",
      "iter 740001 cost: 15.193217\n",
      "iter 750001 cost: 15.192299\n",
      "iter 760001 cost: 15.192549\n",
      "iter 770001 cost: 15.192914\n",
      "iter 780001 cost: 15.189517\n",
      "iter 790001 cost: 15.189882\n",
      "iter 800001 cost: 15.196762\n",
      "iter 810001 cost: 15.196270\n",
      "iter 820001 cost: 15.195351\n",
      "iter 830001 cost: 15.191254\n",
      "iter 840001 cost: 15.191619\n",
      "iter 850001 cost: 15.198499\n",
      "iter 860001 cost: 15.198864\n",
      "iter 870001 cost: 15.191479\n",
      "iter 880001 cost: 15.191622\n",
      "iter 890001 cost: 15.198403\n",
      "iter 900001 cost: 15.197485\n",
      "iter 910001 cost: 15.190324\n",
      "iter 920001 cost: 15.190689\n",
      "iter 930001 cost: 15.195287\n",
      "iter 940001 cost: 15.194368\n",
      "iter 950001 cost: 15.191696\n",
      "iter 960001 cost: 15.192061\n",
      "iter 970001 cost: 15.192426\n",
      "iter 980001 cost: 15.199307\n",
      "iter 990001 cost: 15.189394\n",
      "[[-4.05984006  3.25366424]] [6.90041563]\n"
     ]
    }
   ],
   "source": [
    "def grad_descent(w0, eta):\n",
    "    w = w0\n",
    "    it = 0 \n",
    "    while it < 1000000:\n",
    "        it = it + 1\n",
    "        g = grad(w)\n",
    "        w -= eta*g\n",
    "        if (it % 10000) == 1:\n",
    "            print('iter %d' %it + ' cost: %f' %cost(w))\n",
    "        if np.linalg.norm(g) < 1e-7:\n",
    "            break \n",
    "    return w \n",
    "w0 = np.random.randn(X0_bar.shape[0], 1) \n",
    "w = grad_descent(w0, 0.001)\n",
    "w_hinge = w[:-1].reshape(-1, 1)\n",
    "b_hinge = w[-1]\n",
    "print(w_hinge.T, b_hinge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "265c270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bài Thực  Hành số 1\n",
    "# build function to predict\n",
    "def predict_(w, w0, X):\n",
    "  return np.sign(np.dot(w.T, X) + w0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82f22e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.965\n",
      "confusion_matrix: [[94  6]\n",
      " [ 1 99]]\n"
     ]
    }
   ],
   "source": [
    "# method 1\n",
    "w1_1 = np.array([[-3.49216868,  2.83441828]])\n",
    "w1_0 = 6.218000342653659\n",
    "y_pred1 = predict_(w1_1.T, w1_0, X)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "print('accuracy:', accuracy_score(y.ravel(), y_pred1.ravel()))\n",
    "print('confusion_matrix:', confusion_matrix(y.ravel(), y_pred1.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21c6263b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.965\n",
      "confusion_matrix: [[94  6]\n",
      " [ 1 99]]\n"
     ]
    }
   ],
   "source": [
    "# method 2\n",
    "w2_1 = np.array([[-3.49143421,  2.83300814]])\n",
    "w2_0 = [6.21730668]\n",
    "y_pred2 = predict_(w2_1.T, w2_0, X)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "print('accuracy:', accuracy_score(y.ravel(), y_pred2.ravel()))\n",
    "print('confusion_matrix:', confusion_matrix(y.ravel(), y_pred2.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "206fadcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.965\n",
      "confusion_matrix: [[ 93   7]\n",
      " [  0 100]]\n"
     ]
    }
   ],
   "source": [
    "# method 3\n",
    "w3_1 = np.array([[-3.8281209,   1.97956923]])\n",
    "w3_0 = [8.56016034]\n",
    "y_pred3 = predict_(w3_1.T, w3_0, X)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "print('accuracy:', accuracy_score(y.ravel(), y_pred3.ravel()))\n",
    "print('confusion_matrix:', confusion_matrix(y.ravel(), y_pred3.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c15d7766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.245e+01 1.570e+01 8.257e+01 4.771e+02 1.278e-01 1.700e-01 1.578e-01\n",
      " 8.089e-02 2.087e-01 7.613e-02 3.345e-01 8.902e-01 2.217e+00 2.719e+01\n",
      " 7.510e-03 3.345e-02 3.672e-02 1.137e-02 2.165e-02 5.082e-03 1.547e+01\n",
      " 2.375e+01 1.034e+02 7.416e+02 1.791e-01 5.249e-01 5.355e-01 1.741e-01\n",
      " 3.985e-01 1.244e-01]\n",
      "(569, 30)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "#Bài tập thực hành số 2\n",
    "from sklearn import datasets\n",
    "cancer_data = datasets.load_breast_cancer()\n",
    "\n",
    "# show to test record 5th\n",
    "print(cancer_data.data[5])\n",
    "\n",
    "print(cancer_data.data.shape)\n",
    "# target set\n",
    "print(cancer_data.target)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer_data = datasets.load_breast_cancer()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer_data.data, \n",
    "                                                    cancer_data.target,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a23e9b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=100, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=100, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=100, kernel='linear')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel = 'linear', C = 100)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56d91ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9473684210526315\n",
      "confusion_matrix: [[ 59   4]\n",
      " [  5 103]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print('accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('confusion_matrix:', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "439289c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "3  0.0040  0.0117   R  \n",
       "4  0.0107  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bài tập tự giải\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('sonar.all-data.csv', header = None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f72e5864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032  -1  \n",
       "1  0.0052  0.0044  -1  \n",
       "2  0.0095  0.0078  -1  \n",
       "3  0.0040  0.0117  -1  \n",
       "4  0.0107  0.0094  -1  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[60] = df[60].replace({'R': -1, 'M': 1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b344c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = df.drop(columns = [60], axis = 1)\n",
    "labels = df[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4f5966a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 60)\n",
      "(208,)\n"
     ]
    }
   ],
   "source": [
    "print(Data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c7b4670",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Data, labels, test_size = 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62d9a9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=100, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=100, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=100, kernel='linear')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(kernel = 'linear', C = 100)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19b4e4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7142857142857143\n",
      "confusion_matrix: [[20  8]\n",
      " [10 25]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print('accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('confusion_matrix:', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5557a0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ví dụ 3\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d0b85223",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!unzip spambase.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e5fafd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3     4     5     6     7     8     9   ...    48  \\\n",
       "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.00   \n",
       "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.00   \n",
       "2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.01   \n",
       "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "\n",
       "      49   50     51     52     53     54   55    56  57  \n",
       "0  0.000  0.0  0.778  0.000  0.000  3.756   61   278   1  \n",
       "1  0.132  0.0  0.372  0.180  0.048  5.114  101  1028   1  \n",
       "2  0.143  0.0  0.276  0.184  0.010  9.821  485  2259   1  \n",
       "3  0.137  0.0  0.137  0.000  0.000  3.537   40   191   1  \n",
       "4  0.135  0.0  0.135  0.000  0.000  3.537   40   191   1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('spambase.data', header = None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10372d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[57].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bfad8744",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[57] = df[57].replace({0 : -1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60e5ede3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.142</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.555</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.404</td>\n",
       "      <td>6</td>\n",
       "      <td>118</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.147</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1     2    3     4     5    6    7    8    9   ...     48     49  \\\n",
       "4596  0.31  0.0  0.62  0.0  0.00  0.31  0.0  0.0  0.0  0.0  ...  0.000  0.232   \n",
       "4597  0.00  0.0  0.00  0.0  0.00  0.00  0.0  0.0  0.0  0.0  ...  0.000  0.000   \n",
       "4598  0.30  0.0  0.30  0.0  0.00  0.00  0.0  0.0  0.0  0.0  ...  0.102  0.718   \n",
       "4599  0.96  0.0  0.00  0.0  0.32  0.00  0.0  0.0  0.0  0.0  ...  0.000  0.057   \n",
       "4600  0.00  0.0  0.65  0.0  0.00  0.00  0.0  0.0  0.0  0.0  ...  0.000  0.000   \n",
       "\n",
       "       50     51   52   53     54  55   56  57  \n",
       "4596  0.0  0.000  0.0  0.0  1.142   3   88  -1  \n",
       "4597  0.0  0.353  0.0  0.0  1.555   4   14  -1  \n",
       "4598  0.0  0.000  0.0  0.0  1.404   6  118  -1  \n",
       "4599  0.0  0.000  0.0  0.0  1.147   5   78  -1  \n",
       "4600  0.0  0.125  0.0  0.0  1.250   5   40  -1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "72935f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "sc = MinMaxScaler(feature_range= (0, 1))\n",
    "Data = sc.fit_transform(df.drop(columns =[57], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "057391eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Data, df[57], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e7638d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3220, 57), (3220,))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb647368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=100, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=100, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=100, kernel='linear')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(kernel = 'linear', C=100)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05f8e75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9254163649529327\n",
      "confusion_matrix: [[765  39]\n",
      " [ 64 513]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print('accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('confusion_matrix:', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f063c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
